{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Iterative Financial Research Agent with AgentUp\n",
    "\n",
    "### Overview\n",
    "\n",
    "This notebook walks you through the process of building a financial research agent with AgentUp, powered by the\n",
    "`agentup_systools` and `agentup_brave` plugins.\n",
    "\n",
    "Instead of stopping at a single query, this agent learns to dig deeper‚Äîgathering information from multiple sources, refining its\n",
    "analysis step by step, and storing insights locally for later use.\n",
    "\n",
    "Along the way, you‚Äôll see how the agent can search markets in real time‚Äîwhether that‚Äôs equities, crypto, or broader financial\n",
    "trends‚Äîthen sharpen its conclusions as it processes the results.\n",
    "\n",
    "Because all findings can be saved as structured files, the workflow balances immediate insights with a persistent knowledge base.\n",
    "The result is a system that not only reacts but also builds a record of its reasoning.\n",
    "\n",
    "By working through the notebook, you‚Äôll gain practical experience with:\n",
    "\n",
    "- The plugin architecture that allows AgentUp to expand its capabilities\n",
    "- Designing iterative research loops that improve with each cycle\n",
    "- Setting up the necessary security scopes and API keys to keep things safe and controlled\n",
    "- Orchestrating multiple plugins so they function as a unified agent\n",
    "\n",
    "And finally, shaping these techniques into production-ready applications\n",
    "\n",
    "Think of this as both a hands-on tutorial and a foundation for building more advanced, domain-specific research agents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About AgentUp\n",
    "\n",
    "[AgentUp](https://github.com/RedDotRocket/AgentUp) is the framework every forward-looking developer will love - just as Docker redefined application deployment, AgentUp lets you define AI agents with simple config and run them anywhere, instantly. It‚Äôs built by engineers who crafted mission-critical software for Google, GitHub, Nvidia, Shopify and Red Hat, so it scales, secures, and simplifies agent development with enterprise-grade features right out of the box, and a plugin ecosystem that carries your security, middleware, and CI/CD pipelines for you‚Äîif you‚Äôre not already learning it, you‚Äôre letting the future of AI agent infrastructure pass you by.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites and Setup\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. **Brave Search API key** (get from https://api.search.brave.com/) - there is a good free tier available, no credit card required.\n",
    "2. **OpenAI, Anthropic API Keys** or.\n",
    "3. **Ollama** configured!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Required files (Colab only)\n",
    "\n",
    "Note: This section only need be run if using Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "def detect_environment():\n",
    "    \"\"\"Detect the current runtime environment and return appropriate project path.\"\"\"\n",
    "    try:\n",
    "        import google.colab\n",
    "        return 'colab', '/content/proj-folder'\n",
    "    except ImportError:\n",
    "        return 'local', '.'\n",
    "\n",
    "# Environment setup\n",
    "ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "print(f\"Detected environment: {ENV_TYPE}\")\n",
    "print(f\"Project path: {PROJ_PATH}\")\n",
    "\n",
    "if ENV_TYPE == 'colab':\n",
    "    print(\"Setting up Google Colab environment...\")\n",
    "\n",
    "    # Clone the repository if it doesn't exist\n",
    "    if not os.path.exists(PROJ_PATH):\n",
    "        print(\"Cloning agentup-financial-research repository...\")\n",
    "        subprocess.run([\n",
    "            'git', 'clone',\n",
    "            'https://github.com/RedDotRocket/agentup-financial-research',\n",
    "            'proj-folder'\n",
    "        ], check=True)\n",
    "        print(\"Repository cloned to proj-folder\")\n",
    "    else:\n",
    "        print(\"Project folder already exists\")\n",
    "\n",
    "    # Add the repo to Python path\n",
    "    if PROJ_PATH not in sys.path:\n",
    "        sys.path.insert(0, PROJ_PATH)\n",
    "        print(f\"Added {PROJ_PATH} to Python path\")\n",
    "\n",
    "    # Change working directory\n",
    "    os.chdir(PROJ_PATH)\n",
    "    print(f\"Changed working directory to: {PROJ_PATH}\")\n",
    "\n",
    "else:\n",
    "    print(\"Local environment detected - using current directory\")\n",
    "    print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "print(\"Environment setup complete!\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(f\"Python path includes project: {os.getcwd() in sys.path}\")\n",
    "\n",
    "# Make the function globally available for other cells\n",
    "globals()['detect_environment'] = detect_environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "Install the required Python packages using pip.\n",
    "\n",
    "If in Google Colab, we use --quiet mode which prevents the Kernel from being unnecessarily restarted, for a transient dependency 'psutil'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment-aware installation with quiet mode for Colab\n",
    "try:\n",
    "    ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "    print(f\"Using project path: {PROJ_PATH}\")\n",
    "\n",
    "    # Set pip flags based on environment\n",
    "    if ENV_TYPE == 'colab':\n",
    "        pip_flags = \"--quiet\"\n",
    "        print(\"Google Colab detected - using quiet installation mode\")\n",
    "    else:\n",
    "        pip_flags = \"\"\n",
    "        print(\"Local environment - using standard installation mode\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"Warning: detect_environment() not found. Run the Environment Setup cell first.\")\n",
    "    # Fallback detection\n",
    "    try:\n",
    "        import google.colab\n",
    "        PROJ_PATH = \"/content/proj-folder\"\n",
    "        pip_flags = \"--quiet\"\n",
    "        print(\"Fallback: Google Colab detected - using quiet installation mode\")\n",
    "    except ImportError:\n",
    "        PROJ_PATH = \".\"\n",
    "        pip_flags = \"\"\n",
    "        print(\"Fallback: Local environment - using standard installation mode\")\n",
    "\n",
    "print(f\"Using project path: {PROJ_PATH}\")\n",
    "print(\"Installing AgentUp and dependencies...\")\n",
    "\n",
    "# Install AgentUp and plugins\n",
    "%pip install {pip_flags} agentup\n",
    "\n",
    "# Additional dependencies and AgentUp plugins\n",
    "%pip install {pip_flags} -r {PROJ_PATH}/requirements.txt\n",
    "%pip install {pip_flags} -r {PROJ_PATH}/agentup-requirements.txt\n",
    "\n",
    "print(\"Installation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check plugin status\n",
    "\n",
    "Check the plugins are loaded and ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!agentup plugin list -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Model Provider and Brave Search API Key\n",
    "\n",
    "The following keys are required:\n",
    "\n",
    "- **Brave Search API**: Free tier available at [Brave Search API](https://api.search.brave.com/)\n",
    "- **AI Provider Options**:\n",
    "  - **OpenAI API**: Get your key from [OpenAI Platform](https://platform.openai.com/api-keys) - Excellent tool calling\n",
    "  - **Anthropic API**: Get your key from [Anthropic Console](https://console.anthropic.com/) - Superior reasoning\n",
    "  - **Ollama**: Local deployment at [Ollama.ai](https://ollama.ai/) - ‚ö†Ô∏è Requires models capable of tool calling\n",
    "\n",
    "**üí° If running locally**: Set environment variables before starting Jupyter:\n",
    "```bash\n",
    "# Required for all configurations\n",
    "export BRAVE_API_KEY='your-brave-api-key-here'\n",
    "\n",
    "# Choose your AI provider (pick one):\n",
    "export OPENAI_API_KEY='your-openai-api-key-here'        # Option 1: OpenAI (default)\n",
    "export ANTHROPIC_API_KEY='your-anthropic-api-key-here'  # Option 2: Anthropic  \n",
    "export OLLAMA_BASE_URL='http://localhost:11434'         # Option 3: Ollama\n",
    "\n",
    "jupyter lab\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def mask_key(key, show_first=4, show_last=4):\n",
    "    \"\"\"Mask an API key for display, showing only first and last characters.\"\"\"\n",
    "    if not key or len(key) < 8:\n",
    "        return '***'\n",
    "    return f\"{key[:show_first]}{'*' * (len(key) - show_first - show_last)}{key[-show_last:]}\"\n",
    "\n",
    "# Enhanced environment setup supporting multiple AI providers\n",
    "def setup_environment():\n",
    "    \"\"\"Set up API keys with multi-provider support and masked input.\"\"\"\n",
    "\n",
    "    # Check required keys\n",
    "    missing_keys = []\n",
    "    if not os.getenv('BRAVE_API_KEY'):\n",
    "        missing_keys.append('BRAVE_API_KEY')\n",
    "\n",
    "    # AI Provider Selection\n",
    "    ai_provider = None\n",
    "    ai_key_required = None\n",
    "\n",
    "    # Check if any AI provider is already configured\n",
    "    existing_providers = []\n",
    "    if os.getenv('OPENAI_API_KEY'):\n",
    "        existing_providers.append('OpenAI')\n",
    "    if os.getenv('ANTHROPIC_API_KEY'):\n",
    "        existing_providers.append('Anthropic')\n",
    "    if os.getenv('OLLAMA_BASE_URL'):\n",
    "        existing_providers.append('Ollama')\n",
    "\n",
    "    if missing_keys or not existing_providers:\n",
    "        print(\"API Key Configuration Required\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if existing_providers:\n",
    "            print(f\"‚úÖ Detected existing providers: {', '.join(existing_providers)}\")\n",
    "\n",
    "        if missing_keys:\n",
    "            print(\"Missing environment variables:\", ', '.join(missing_keys))\n",
    "\n",
    "        # AI Provider Selection if none configured\n",
    "        if not existing_providers:\n",
    "            print(\"\\nAI Provider Selection:\")\n",
    "            print(\"We need to choose which AI provider to use for this agent.\")\n",
    "\n",
    "            try:\n",
    "                # VSCode-friendly input with options in the prompt\n",
    "                ai_choice = input(\"\\nChoose AI Provider: (1) OpenAI GPT-4o-mini [reliable] (2) Anthropic Claude-3.5-Sonnet [reasoning] (3) Ollama [local/private] (4) Skip - Enter 1-4: \").strip()\n",
    "\n",
    "                if ai_choice == \"1\":\n",
    "                    ai_provider = \"openai\"\n",
    "                    ai_key_required = \"OPENAI_API_KEY\"\n",
    "                    print(\"‚úÖ Selected: OpenAI (GPT-4o-mini) - Excellent tool calling capabilities\")\n",
    "                elif ai_choice == \"2\":\n",
    "                    ai_provider = \"anthropic\"\n",
    "                    ai_key_required = \"ANTHROPIC_API_KEY\"\n",
    "                    print(\"‚úÖ Selected: Anthropic (Claude 3.5 Sonnet) - Superior reasoning\")\n",
    "                elif ai_choice == \"3\":\n",
    "                    ai_provider = \"ollama\"\n",
    "                    ai_key_required = \"OLLAMA_BASE_URL\"\n",
    "                    print(\"‚úÖ Selected: Ollama (Local deployment)\")\n",
    "                    print(\"‚ö†Ô∏è WARNING: Use 30B+ models (llama3.1:70b, qwen2.5:32b, mixtral:8x7b)\")\n",
    "                    print(\"Small models (8b) often fail with tools!\")\n",
    "                elif ai_choice == \"4\":\n",
    "                    ai_provider = None\n",
    "                    print(\"Skipping AI provider setup\")\n",
    "                else:\n",
    "                    print(\"Invalid choice, defaulting to OpenAI\")\n",
    "                    ai_provider = \"openai\"\n",
    "                    ai_key_required = \"OPENAI_API_KEY\"\n",
    "\n",
    "            except (KeyboardInterrupt, EOFError):\n",
    "                print(\"\\nDefaulting to OpenAI configuration\")\n",
    "                ai_provider = \"openai\"\n",
    "                ai_key_required = \"OPENAI_API_KEY\"\n",
    "\n",
    "        # Get required keys with masked input\n",
    "        try:\n",
    "            # Brave Search API Key (always required)\n",
    "            if 'BRAVE_API_KEY' in missing_keys:\n",
    "                print(\"\\nBRAVE SEARCH API KEY REQUIRED\")\n",
    "                print(\"   Purpose: Enables internet search for financial data\")\n",
    "                print(\"   Get free key at: https://api.search.brave.com/\")\n",
    "                print(\"   Sign up ‚Üí Create App ‚Üí Copy API key\")\n",
    "\n",
    "                value = getpass.getpass(\"\\n   Enter your Brave Search API key (input will be hidden): \").strip()\n",
    "\n",
    "                if value:\n",
    "                    os.environ['BRAVE_API_KEY'] = value\n",
    "                    print(f\"   ‚úÖ BRAVE_API_KEY configured successfully: {mask_key(value)}\")\n",
    "                else:\n",
    "                    print(\"   ‚ùå BRAVE_API_KEY cannot be empty\")\n",
    "                    return False, None\n",
    "\n",
    "            # AI Provider Key\n",
    "            if ai_key_required and not os.getenv(ai_key_required):\n",
    "                if ai_provider == \"openai\":\n",
    "                    print(\"\\nOPENAI API KEY REQUIRED\")\n",
    "                    print(\"   Purpose: Powers the AI agent (GPT-4o-mini model)\")\n",
    "                    print(\"   Get key at: https://platform.openai.com/api-keys\")\n",
    "                    print(\"   Login ‚Üí Create new secret key ‚Üí Copy key\")\n",
    "                    value = getpass.getpass(\"\\n   Enter your OpenAI API key (input will be hidden): \").strip()\n",
    "\n",
    "                elif ai_provider == \"anthropic\":\n",
    "                    print(\"\\nANTHROPIC API KEY REQUIRED\")\n",
    "                    print(\"   Purpose: Powers the AI agent (Claude 3.5 Sonnet)\")\n",
    "                    print(\"   Get key at: https://console.anthropic.com/\")\n",
    "                    print(\"   Login ‚Üí API Keys ‚Üí Create Key ‚Üí Copy key\")\n",
    "                    value = getpass.getpass(\"\\n   Enter your Anthropic API key (input will be hidden): \").strip()\n",
    "\n",
    "                elif ai_provider == \"ollama\":\n",
    "                    print(\"\\nOLLAMA CONFIGURATION\")\n",
    "                    print(\"   Purpose: Local AI model deployment\")\n",
    "                    print(\"   Default: http://localhost:11434\")\n",
    "                    print(\"   Make sure Ollama is running with a large model!\")\n",
    "                    value = input(\"\\n   Enter Ollama base URL [http://localhost:11434] or press Enter for default: \").strip()\n",
    "                    if not value:\n",
    "                        value = \"http://localhost:11434\"\n",
    "\n",
    "                if value:\n",
    "                    os.environ[ai_key_required] = value\n",
    "                    if ai_provider == \"ollama\":\n",
    "                        print(f\"   ‚úÖ {ai_key_required} configured successfully: {value}\")\n",
    "                    else:\n",
    "                        print(f\"   ‚úÖ {ai_key_required} configured successfully: {mask_key(value)}\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå {ai_key_required} cannot be empty\")\n",
    "                    return False, None\n",
    "\n",
    "        except (KeyboardInterrupt, EOFError):\n",
    "            print(\"\\n‚ùå Setup cancelled by user\")\n",
    "            return False, None\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error during setup: {e}\")\n",
    "            return False, None\n",
    "\n",
    "    # Verify configuration with masked display\n",
    "    brave_key = os.getenv('BRAVE_API_KEY', '')\n",
    "\n",
    "    # Check which AI provider is configured\n",
    "    openai_key = os.getenv('OPENAI_API_KEY', '')\n",
    "    anthropic_key = os.getenv('ANTHROPIC_API_KEY', '')\n",
    "    ollama_url = os.getenv('OLLAMA_BASE_URL', '')\n",
    "\n",
    "    configured_provider = None\n",
    "    if openai_key:\n",
    "        configured_provider = \"openai\"\n",
    "    elif anthropic_key:\n",
    "        configured_provider = \"anthropic\"\n",
    "    elif ollama_url:\n",
    "        configured_provider = \"ollama\"\n",
    "\n",
    "    if brave_key and (configured_provider or ai_provider is None):\n",
    "        print(\"\\n‚úÖ Environment configured successfully!\")\n",
    "        print(\"API Keys Status:\")\n",
    "        print(f\"   BRAVE_API_KEY: {mask_key(brave_key)}\")\n",
    "\n",
    "        if configured_provider == \"openai\":\n",
    "            print(f\"   OPENAI_API_KEY: {mask_key(openai_key)}\")\n",
    "            print(\"   AI Provider: OpenAI (GPT-4o-mini)\")\n",
    "        elif configured_provider == \"anthropic\":\n",
    "            print(f\"   ANTHROPIC_API_KEY: {mask_key(anthropic_key)}\")\n",
    "            print(\"   AI Provider: Anthropic (Claude 3.5 Sonnet)\")\n",
    "        elif configured_provider == \"ollama\":\n",
    "            print(f\"   OLLAMA_BASE_URL: {ollama_url}\")\n",
    "            print(\"   AI Provider: Ollama (Local deployment)\")\n",
    "            print(\"   ‚ö†Ô∏è Ensure your model supports tool calling (30B+ recommended)\")\n",
    "\n",
    "        return True, configured_provider or ai_provider\n",
    "    else:\n",
    "        print(\"\\n‚ùå Setup incomplete - missing required keys\")\n",
    "        return False, None\n",
    "\n",
    "print(\"=\" * 50)\n",
    "\n",
    "success, provider = setup_environment()\n",
    "if success:\n",
    "    print(f\"\\nReady for AgentUp tutorial with {provider or 'configured'} provider!\")\n",
    "    print(\"You can now proceed to the next cell.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Environment setup needed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Configuration\n",
    "\n",
    "We'll configure our financial research agent with the necessary plugins and security scopes. The configuration follows AgentUp's declarative approach where plugins declare their requirements.\n",
    "\n",
    "### Understanding Plugin Architecture\n",
    "\n",
    "- **agentup_systools**: Provides file operations, directory management, and command execution\n",
    "- **agentup_brave**: Enables web search capabilities through Brave Search API\n",
    "- **Security Scopes**: Fine-grained permissions (`files:read`, `files:write`, `api:read`, `system:read`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive AgentUp Configuration (Real AgentUp Format)\n",
    "from jinja2 import Template\n",
    "from pathlib import Path\n",
    "from agent_configs import AGENT_CONFIGS\n",
    "\n",
    "def show_agent_options():\n",
    "    \"\"\"Display available agent configurations\"\"\"\n",
    "    print(\"ü§ñ Available AgentUp Configurations\")\n",
    "    print(\"=\" * 50)\n",
    "    for key, config in AGENT_CONFIGS.items():\n",
    "        print(f\"\\nüìã {key.upper()}\")\n",
    "        print(f\"   Name: {config['name']}\")\n",
    "        print(f\"   Description: {config['description']}\")\n",
    "        print(f\"   System Prompt: {len(config['system_prompt'])} characters\")\n",
    "    print()\n",
    "\n",
    "def get_user_choice():\n",
    "    \"\"\"Get user's agent choice\"\"\"\n",
    "    print(\"Which agent would you like to configure?\")\n",
    "    print(\"1. Financial Research Agent (recommended)\")\n",
    "    print(\"2. Weather Analysis Agent\")\n",
    "    print(\"3. Technical Support Agent\")\n",
    "    print(\"4. Keep existing configuration\")\n",
    "\n",
    "    try:\n",
    "        choice = input(\"\\nEnter choice (1-4): \").strip()\n",
    "        choice_map = {\"1\": \"financial\", \"2\": \"weather\", \"3\": \"technical\", \"4\": \"existing\"}\n",
    "        return choice_map.get(choice, \"financial\")\n",
    "    except (KeyboardInterrupt, EOFError):\n",
    "        print(\"\\nUsing default financial configuration\")\n",
    "        return \"financial\"\n",
    "\n",
    "def create_agentup_yaml_from_template():\n",
    "    \"\"\"Create AgentUp YAML using real AgentUp format\"\"\"\n",
    "\n",
    "    # Show options and get choice\n",
    "    show_agent_options()\n",
    "    choice = get_user_choice()\n",
    "\n",
    "    if choice == \"existing\":\n",
    "        print(\"\\n‚úÖ Keeping existing agentup.yml configuration\")\n",
    "        return \"existing\"\n",
    "\n",
    "    selected_config = AGENT_CONFIGS[choice]\n",
    "    print(f\"\\n‚úÖ Selected: {selected_config['name']}\")\n",
    "\n",
    "    # Load the Jinja2 template\n",
    "    template_path = Path(\"./agentup.yml.j2\")\n",
    "    if not template_path.exists():\n",
    "        print(f\"‚ùå Template file not found: {template_path}\")\n",
    "        return \"error\"\n",
    "\n",
    "    with open(template_path, 'r') as f:\n",
    "        template_content = f.read()\n",
    "\n",
    "    # Create Jinja2 template\n",
    "    template = Template(template_content)\n",
    "\n",
    "    # Render the template with selected configuration\n",
    "    rendered_yaml = template.render(\n",
    "        name=selected_config['name'],\n",
    "        description=selected_config['description'],\n",
    "        system_prompt=selected_config['system_prompt']\n",
    "    )\n",
    "\n",
    "    # Write the rendered YAML\n",
    "    config_path = Path(\"./agentup.yml\")\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(rendered_yaml)\n",
    "\n",
    "    print(\"‚úÖ AgentUp configuration generated from template\")\n",
    "    print(f\"üìÅ Template: {template_path}\")\n",
    "    print(f\"üìÅ Output: {config_path}\")\n",
    "    print(\"üß© System prompt: {len(selected_config['system_prompt'])} characters\")\n",
    "    print(\"üìê Format: Real AgentUp YAML structure\")\n",
    "    print(\"üéØ Features: agent_type=iterative, memory_config, iterative_config\")\n",
    "\n",
    "    return config_path\n",
    "\n",
    "# Install Jinja2 if not available\n",
    "try:\n",
    "    from jinja2 import Template\n",
    "    print(\"‚úÖ Jinja2 available\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing Jinja2...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"jinja2\"])\n",
    "    print(\"‚úÖ Jinja2 installed\")\n",
    "    from jinja2 import Template\n",
    "\n",
    "# Run the configuration setup\n",
    "print(\"üöÄ AgentUp Configuration Setup (Real AgentUp Format)\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "config_result = create_agentup_yaml_from_template()\n",
    "\n",
    "if config_result != \"existing\" and config_result != \"error\":\n",
    "    print(\"\\n Ready to use AgentUp!\")\n",
    "    print(\"üìÅ Configuration file: {config_result}\")\n",
    "elif config_result == \"existing\":\n",
    "    print(\"\\n Using existing agentup.yml configuration\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Configuration setup failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Research Directories and Conversation States\n",
    "\n",
    "We need to ensure that the necessary directories for research data and conversation states are set up properly. This will help in organizing our files and maintaining a clean project structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use environment-aware paths for directory creation\n",
    "from pathlib import Path\n",
    "try:\n",
    "    ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "    base_path = Path(PROJ_PATH)\n",
    "    print(f\"Using base path: {base_path}\")\n",
    "except NameError:\n",
    "    print(\"Warning: detect_environment() not found. Using current directory.\")\n",
    "    base_path = Path(\".\")\n",
    "\n",
    "# Create research data directory for our agent\n",
    "research_dir = base_path / \"research_data\"\n",
    "research_dir.mkdir(exist_ok=True)\n",
    "print(f\"‚úì Research directory created: {research_dir}\")\n",
    "\n",
    "# Create conversation states directory for AgentUp state management\n",
    "states_dir = base_path / \"conversation_states\"\n",
    "states_dir.mkdir(exist_ok=True)\n",
    "print(f\"‚úì Conversation states directory created: {states_dir}\")\n",
    "\n",
    "# Verify AgentUp configuration exists\n",
    "config_path = base_path / \"agentup.yml\"\n",
    "if config_path.exists():\n",
    "    print(f\"‚úì AgentUp configuration ready: {config_path}\")\n",
    "    print(f\"   Size: {config_path.stat().st_size} bytes\")\n",
    "else:\n",
    "    print(f\"‚ùå AgentUp configuration not found: {config_path}\")\n",
    "    print(\"   Please run the previous cell to generate the configuration\")\n",
    "\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "print(f\"Research data will be saved to: {research_dir.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start the AgentUp Server\n",
    "\n",
    "Now that our plugins and configuration file is created, we can start the AgentUp server to begin using our financial research agent. Run the following command in your terminal:\n",
    "\n",
    "This will start the server with the specified configuration, allowing you to interact with the agent and perform research tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Google Colab port forwarding (graceful fallback)\n",
    "try:\n",
    "    import google.colab\n",
    "    from google.colab import output\n",
    "    output.serve_kernel_port_as_window(8000)\n",
    "    print(\"Google Colab detected - port 8000 forwarding enabled\")\n",
    "except ImportError:\n",
    "    print(\"Standard Jupyter environment - port forwarding not needed\")\n",
    "\n",
    "def run_server():\n",
    "    \"\"\"Run the AgentUp server in a background thread.\"\"\"\n",
    "    try:\n",
    "        # Use the config file path\n",
    "        config_path = \"./agentup.yml\"\n",
    "\n",
    "        # Start the server without capturing output (let it run freely)\n",
    "        subprocess.Popen([\n",
    "            \"agentup\", \"run\",\n",
    "            \"--config\", config_path,\n",
    "            \"--no-reload\"\n",
    "        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "        print(\"Server process started\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to start server: {e}\")\n",
    "\n",
    "# Start server in background thread\n",
    "print(\"Starting AgentUp Server in Background Thread...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n",
    "\n",
    "# Give the server time to start\n",
    "print(\"Waiting for server to initialize...\")\n",
    "for i in range(10):\n",
    "    time.sleep(1)\n",
    "    print(f\"   Starting... {i+1}/10\", end=\"\\r\")\n",
    "\n",
    "print(\"\\nServer should be running in background!\")\n",
    "print(\"Server URL: http://localhost:8000\")\n",
    "print(\"API Key: research-agent-key-123\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: If the server fails to start, check the AgentUp configuration\")\n",
    "print(\"   and ensure all required API keys are set in environment variables.\")\n",
    "print(\"\\nYou can now proceed to test the agent connectivity in the next cell!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent-to-Agent (A2A) Communication\n",
    "\n",
    "AgentUp uses the A2A protocol for communication. We'll create helper functions to interact with our agent using JSON-RPC format.\n",
    "\n",
    "### Understanding A2A Protocol\n",
    "\n",
    "The A2A protocol enables standardized communication between agents with:\n",
    "- **JSON-RPC 2.0** format for requests\n",
    "- **Message-based** communication with structured parts\n",
    "- **Security-first** design with authentication headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "from typing import Any, Optional, Callable\n",
    "\n",
    "class FinancialResearchAgent:\n",
    "    \"\"\"Client for interacting with the Financial Research Agent via A2A streaming protocol.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str = \"http://localhost:8000\", api_key: str = \"research-agent-key-123\"):\n",
    "        self.base_url = base_url\n",
    "        self.api_key = api_key\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-API-Key\": api_key\n",
    "        }\n",
    "        self.message_counter = 0\n",
    "\n",
    "    def _create_stream_message(self, text: str, message_id: Optional[str] = None) -> dict[str, Any]:\n",
    "        \"\"\"Create a properly formatted A2A message for streaming.\"\"\"\n",
    "        if message_id is None:\n",
    "            message_id = f\"msg-{int(time.time())}-{self.message_counter}\"\n",
    "            self.message_counter += 1\n",
    "\n",
    "        return {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"method\": \"message/stream\",\n",
    "            \"params\": {\n",
    "                \"message\": {\n",
    "                    \"role\": \"user\",\n",
    "                    \"parts\": [\n",
    "                        {\n",
    "                            \"kind\": \"text\",\n",
    "                            \"text\": text\n",
    "                        }\n",
    "                    ],\n",
    "                    \"message_id\": message_id,\n",
    "                    \"kind\": \"message\"\n",
    "                }\n",
    "            },\n",
    "            \"id\": f\"req-{message_id}\"\n",
    "        }\n",
    "\n",
    "    def _parse_streaming_response(self, line: str) -> tuple[Optional[str], bool]:\n",
    "        \"\"\"Parse a streaming response line and extract readable content.\"\"\"\n",
    "        try:\n",
    "            # Remove 'data: ' prefix if present\n",
    "            if line.startswith('data: '):\n",
    "                line = line[6:]\n",
    "\n",
    "            chunk_data = json.loads(line)\n",
    "\n",
    "            if 'result' in chunk_data:\n",
    "                result = chunk_data['result']\n",
    "\n",
    "                # Handle different message types\n",
    "                if result.get('kind') == 'status-update':\n",
    "                    status = result.get('status', {})\n",
    "                    message = status.get('message', {})\n",
    "                    parts = message.get('parts', [])\n",
    "\n",
    "                    if parts:\n",
    "                        text = parts[0].get('text', '')\n",
    "                        state = status.get('state', '')\n",
    "\n",
    "                        # Format status updates nicely\n",
    "                        if state == 'working' and text:\n",
    "                            return f\"üîÑ {text}\\n\", False\n",
    "                        elif text:\n",
    "                            return f\"üìù {text}\\n\", False\n",
    "\n",
    "                elif result.get('kind') == 'message':\n",
    "                    # Final message content\n",
    "                    parts = result.get('parts', [])\n",
    "                    if parts:\n",
    "                        content = parts[0].get('text', '')\n",
    "                        return content, True\n",
    "\n",
    "                elif 'content' in result:\n",
    "                    # Direct content\n",
    "                    return result['content'], result.get('final', False)\n",
    "\n",
    "            elif 'error' in chunk_data:\n",
    "                return f\"‚ùå Error: {chunk_data['error']}\\n\", True\n",
    "\n",
    "        except json.JSONDecodeError:\n",
    "            # Non-JSON line, might be plain text\n",
    "            if line.strip():\n",
    "                return f\"{line}\\n\", False\n",
    "        except Exception as e:\n",
    "            return f\"‚ö†Ô∏è Parse error: {e}\\n\", False\n",
    "\n",
    "        return None, False\n",
    "\n",
    "    async def send_message_stream(self, text: str, on_chunk: Optional[Callable] = None) -> dict[str, Any]:\n",
    "        \"\"\"Send a message to the agent and return the streaming response.\"\"\"\n",
    "        message = self._create_stream_message(text)\n",
    "\n",
    "        try:\n",
    "            timeout = aiohttp.ClientTimeout(total=300)  # 5 minutes for long research\n",
    "            async with aiohttp.ClientSession(timeout=timeout, headers=self.headers) as session:\n",
    "                async with session.post(self.base_url, json=message) as response:\n",
    "                    response.raise_for_status()\n",
    "\n",
    "                    full_content = \"\"\n",
    "                    final_result = {}\n",
    "                    _is_complete = False\n",
    "\n",
    "                    async for chunk in response.content.iter_chunked(1024):\n",
    "                        if chunk:\n",
    "                            try:\n",
    "                                chunk_text = chunk.decode('utf-8')\n",
    "\n",
    "                                # Process each line separately\n",
    "                                for line in chunk_text.strip().split('\\n'):\n",
    "                                    if not line.strip():\n",
    "                                        continue\n",
    "\n",
    "                                    content, is_final = self._parse_streaming_response(line)\n",
    "\n",
    "                                    if content:\n",
    "                                        full_content += content\n",
    "\n",
    "                                        # Call callback for real-time display\n",
    "                                        if on_chunk:\n",
    "                                            await on_chunk(content)\n",
    "\n",
    "                                        # Check if this is the final response\n",
    "                                        if is_final:\n",
    "                                            final_result = {\n",
    "                                                \"success\": True,\n",
    "                                                \"result\": {\n",
    "                                                    \"content\": content,\n",
    "                                                    \"role\": \"assistant\"\n",
    "                                                }\n",
    "                                            }\n",
    "\n",
    "                            except UnicodeDecodeError:\n",
    "                                continue\n",
    "\n",
    "                    # Return final result\n",
    "                    if final_result:\n",
    "                        return final_result\n",
    "                    else:\n",
    "                        return {\n",
    "                            \"success\": True,\n",
    "                            \"result\": {\n",
    "                                \"content\": full_content,\n",
    "                                \"role\": \"assistant\"\n",
    "                            }\n",
    "                        }\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Streaming request failed: {str(e)}\", \"success\": False}\n",
    "\n",
    "    async def send_message(self, text: str) -> dict[str, Any]:\n",
    "        \"\"\"Send a message to the agent (backwards compatibility).\"\"\"\n",
    "        return await self.send_message_stream(text)\n",
    "\n",
    "    async def research_topic_stream(self, topic: str) -> dict[str, Any]:\n",
    "        \"\"\"Research a financial topic with iterative analysis and streaming display.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        Perform comprehensive financial research on: {topic}\n",
    "\n",
    "        Please follow this iterative process:\n",
    "        1. Search for recent news and data about {topic}\n",
    "        2. Analyze the search results for key trends and insights\n",
    "        3. Create a detailed research report which includes all of your findings.\n",
    "        4. The report should be at least 3000 words + and explain your research process and how it led to specific findings.\n",
    "        4. Save the report to a file in the research_data directory unless in google colab, and then save to content/proj-folder/research_data/\n",
    "        5. Provide a summary of your findings\n",
    "\n",
    "        Focus on:\n",
    "        - Recent market movements and trends\n",
    "        - Key financial metrics and data points\n",
    "        - Expert opinions and analysis (provide quotes, links)\n",
    "        - Potential risks and opportunities\n",
    "\n",
    "        Please use available tools and capabilities to search internet read or write file operations to complete the research.\n",
    "        \"\"\"\n",
    "\n",
    "        print(f\"üîç Starting research on: {topic}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        # Create a callback to display clean streaming content\n",
    "        async def display_chunk(content):\n",
    "            print(content, end='', flush=True)\n",
    "\n",
    "        result = await self.send_message_stream(prompt, display_chunk)\n",
    "        print(f\"\\n{'-' * 60}\")\n",
    "        print(\"‚úÖ Research completed!\")\n",
    "\n",
    "        return result\n",
    "\n",
    "    def research_topic(self, topic: str) -> dict[str, Any]:\n",
    "        \"\"\"Synchronous wrapper for research_topic_stream.\"\"\"\n",
    "        # Check if we're in a notebook environment\n",
    "        try:\n",
    "            from IPython.core.getipython import get_ipython\n",
    "            if get_ipython() is not None:\n",
    "                # We're in Jupyter, use the event loop\n",
    "                loop = asyncio.get_event_loop()\n",
    "                if loop.is_running():\n",
    "                    import nest_asyncio\n",
    "                    nest_asyncio.apply()\n",
    "                return loop.run_until_complete(self.research_topic_stream(topic))\n",
    "            else:\n",
    "                return asyncio.run(self.research_topic_stream(topic))\n",
    "        except RuntimeError:\n",
    "            # Handles \"There is no current event loop in thread\" or similar\n",
    "            return asyncio.run(self.research_topic_stream(topic))\n",
    "        except ImportError:\n",
    "            # Handles missing IPython or nest_asyncio\n",
    "            return asyncio.run(self.research_topic_stream(topic))\n",
    "\n",
    "print(\"‚úì Financial Research Agent client created and ready to use!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Agent Connectivity\n",
    "\n",
    "Let's test that our agent is running and can respond to basic requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "def fetch_agent_card(base_url: str = \"http://127.0.0.1:8000\") -> dict[str, Any]:\n",
    "    \"\"\"Fetch the agent card from the well-known endpoint.\"\"\"\n",
    "    agent_card_url = f\"{base_url}/.well-known/agent-card.json\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(agent_card_url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        raise Exception(f\"Failed to fetch agent card: {e}\")\n",
    "    except json.JSONDecodeError as e:\n",
    "        raise Exception(f\"Invalid JSON response: {e}\")\n",
    "\n",
    "\n",
    "def display_agent_info(agent_card: dict[str, Any]) -> None:\n",
    "    \"\"\"Display basic agent information.\"\"\"\n",
    "    print(\"‚úÖ Agent Card Retrieved Successfully!\")\n",
    "    print(f\"Agent Name: {agent_card.get('name', 'Unknown')}\")\n",
    "    print(f\"Description: {agent_card.get('description', 'No description')}\")\n",
    "    print(f\"URL: {agent_card.get('url', 'No URL')}\")\n",
    "    print(f\"Protocol Version: {agent_card.get('protocolVersion', 'Unknown')}\")\n",
    "    print(f\"AgentUp Version: {agent_card.get('version', 'Unknown')}\")\n",
    "\n",
    "\n",
    "def display_capabilities(capabilities: dict[str, Any]) -> None:\n",
    "    \"\"\"Display agent capabilities.\"\"\"\n",
    "    print(\"\\nCapabilities:\")\n",
    "    print(f\"   Streaming: {capabilities.get('streaming', False)}\")\n",
    "    print(f\"   Push Notifications: {capabilities.get('pushNotifications', False)}\")\n",
    "    print(f\"   State History: {capabilities.get('stateTransitionHistory', False)}\")\n",
    "\n",
    "\n",
    "def display_provider_info(provider: dict[str, Any]) -> None:\n",
    "    \"\"\"Display provider information.\"\"\"\n",
    "    print(\"\\nProvider:\")\n",
    "    print(f\"   Organization: {provider.get('organization', 'Unknown')}\")\n",
    "    print(f\"   URL: {provider.get('url', 'Unknown')}\")\n",
    "\n",
    "\n",
    "def group_skills_by_type(skills: list[dict[str, Any]]) -> dict[str, list[dict[str, Any]]]:\n",
    "    \"\"\"Group skills by their type/plugin.\"\"\"\n",
    "    skill_groups = {\n",
    "        'search': [],\n",
    "        'file_ops': [],\n",
    "        'system_ops': [],\n",
    "        'other': []\n",
    "    }\n",
    "\n",
    "    for skill in skills:\n",
    "        skill_id = skill.get('id', '').lower()\n",
    "\n",
    "        if 'search' in skill_id:\n",
    "            skill_groups['search'].append(skill)\n",
    "        elif 'file' in skill_id or 'directory' in skill_id:\n",
    "            skill_groups['file_ops'].append(skill)\n",
    "        elif any(keyword in skill_id for keyword in ['system', 'command', 'working', 'hash']):\n",
    "            skill_groups['system_ops'].append(skill)\n",
    "        else:\n",
    "            skill_groups['other'].append(skill)\n",
    "\n",
    "    return skill_groups\n",
    "\n",
    "\n",
    "def display_skill_group(title: str, skills: list[dict[str, Any]], max_display: int = 4) -> None:\n",
    "    \"\"\"Display a group of skills with consistent formatting.\"\"\"\n",
    "    if not skills:\n",
    "        return\n",
    "\n",
    "    print(f\"\\n   {title}:\")\n",
    "\n",
    "    for i, skill in enumerate(skills[:max_display]):\n",
    "        name = skill.get('name', 'Unknown')\n",
    "        skill_id = skill.get('id', 'no-id')\n",
    "        description = skill.get('description', 'No description')\n",
    "\n",
    "        # Format for better readability\n",
    "        if len(description) > 60:\n",
    "            description = description[:57] + \"...\"\n",
    "\n",
    "        print(f\"      ‚Ä¢ {name} ({skill_id})\")\n",
    "        print(f\"        {description}\")\n",
    "\n",
    "        # Show example if available\n",
    "        examples = skill.get('examples', [])\n",
    "        if examples and i < 2:  # Only show examples for first 2 skills\n",
    "            example = examples[0] if isinstance(examples[0], str) else str(examples[0])\n",
    "            if len(example) > 50:\n",
    "                example = example[:47] + \"...\"\n",
    "            print(f\"        Example: {example}\")\n",
    "\n",
    "    if len(skills) > max_display:\n",
    "        print(f\"        ... and {len(skills) - max_display} more\")\n",
    "\n",
    "\n",
    "def display_skills(skills: list[dict[str, Any]]) -> None:\n",
    "    \"\"\"Display all available skills grouped by type.\"\"\"\n",
    "    print(f\"\\nAvailable Skills ({len(skills)} total):\")\n",
    "\n",
    "    skill_groups = group_skills_by_type(skills)\n",
    "\n",
    "    # Display each group\n",
    "    display_skill_group(\"Web Search\", skill_groups['search'], max_display=2)\n",
    "    display_skill_group(\"File Operations\", skill_groups['file_ops'], max_display=3)\n",
    "    display_skill_group(\"System Operations\", skill_groups['system_ops'], max_display=3)\n",
    "    display_skill_group(\"Other Tools\", skill_groups['other'], max_display=2)\n",
    "\n",
    "\n",
    "def display_security_info(agent_card: dict[str, Any]) -> None:\n",
    "    \"\"\"Display security configuration.\"\"\"\n",
    "    print(\"\\nSecurity Configuration:\")\n",
    "\n",
    "    security_schemes = agent_card.get('securitySchemes')\n",
    "    if security_schemes:\n",
    "        print(f\"   Security Schemes: {list(security_schemes.keys())}\")\n",
    "    else:\n",
    "        print(\"   Authentication: API Key based (X-API-Key header)\")\n",
    "\n",
    "    # Show security requirements from skills\n",
    "    skills = agent_card.get('skills', [])\n",
    "    scopes_found = set()\n",
    "\n",
    "    for skill in skills:\n",
    "        security = skill.get('security', [])\n",
    "        for sec_req in security:\n",
    "            if 'scopes' in sec_req:\n",
    "                scopes_found.update(sec_req['scopes'])\n",
    "\n",
    "    if scopes_found:\n",
    "        print(f\"   Required Scopes: {', '.join(sorted(scopes_found))}\")\n",
    "\n",
    "\n",
    "def display_communication_info(agent_card: dict[str, Any]) -> None:\n",
    "    \"\"\"Display communication capabilities.\"\"\"\n",
    "    print(\"\\nCommunication:\")\n",
    "    print(f\"   Input Modes: {', '.join(agent_card.get('defaultInputModes', ['text']))}\")\n",
    "    print(f\"   Output Modes: {', '.join(agent_card.get('defaultOutputModes', ['text']))}\")\n",
    "    print(f\"   Transport: {agent_card.get('preferredTransport', 'JSONRPC')}\")\n",
    "\n",
    "\n",
    "def display_insights(agent_card: dict[str, Any]) -> None:\n",
    "    \"\"\"Display key insights about the agent.\"\"\"\n",
    "    capabilities = agent_card.get('capabilities', {})\n",
    "    skills = agent_card.get('skills', [])\n",
    "\n",
    "    print(\"\\nKey Insights:\")\n",
    "\n",
    "    if capabilities.get('streaming'):\n",
    "        print(\"   ‚úÖ Real-time streaming support enables live research feedback\")\n",
    "\n",
    "    if len(skills) >= 10:\n",
    "        print(f\"   ‚úÖ Rich toolset with {len(skills)} capabilities for comprehensive research\")\n",
    "\n",
    "    if any('search' in s.get('id', '') for s in skills):\n",
    "        print(\"   ‚úÖ Web search integration for real-time financial data\")\n",
    "\n",
    "    if any('file' in s.get('id', '') for s in skills):\n",
    "        print(\"   ‚úÖ File operations enable persistent research storage\")\n",
    "\n",
    "    # Check for financial research relevance\n",
    "    description = agent_card.get('description', '').lower()\n",
    "    if 'financial' in description or 'research' in description:\n",
    "        print(\"   ‚úÖ Specialized for financial research and market analysis\")\n",
    "\n",
    "# Execute the agent card discovery directly (notebook-friendly)\n",
    "print(\"Agent Card Discovery Test\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # Fetch the agent card\n",
    "    agent_card = fetch_agent_card()\n",
    "\n",
    "    # Display all information\n",
    "    display_agent_info(agent_card)\n",
    "    display_capabilities(agent_card.get('capabilities', {}))\n",
    "    display_provider_info(agent_card.get('provider', {}))\n",
    "    display_skills(agent_card.get('skills', []))\n",
    "    display_security_info(agent_card)\n",
    "    display_communication_info(agent_card)\n",
    "    display_insights(agent_card)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"The agent card provides a standardized way to discover agent capabilities\")\n",
    "    print(\"This endpoint follows the A2A protocol specification for agent discovery\")\n",
    "    print(\"Use this information to understand what the agent can do before making requests\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Agent card discovery failed: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"   ‚Ä¢ Ensure the AgentUp server is running on http://127.0.0.1:8000\")\n",
    "    print(\"   ‚Ä¢ Check that the agent configuration is valid\")\n",
    "    print(\"   ‚Ä¢ Verify network connectivity to the agent server\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Research\n",
    "\n",
    "Ok Let's perform the research!\n",
    "\n",
    "### Cryptocurrency Market Trends for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the agent client\n",
    "agent = FinancialResearchAgent()\n",
    "\n",
    "# Get environment-appropriate path for file saving\n",
    "try:\n",
    "    ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "    if ENV_TYPE == 'colab':\n",
    "        save_path = \"/content/proj-folder/research_data\"\n",
    "    else:\n",
    "        save_path = \"./research_data\"\n",
    "    print(f\"Research files will be saved to: {save_path}\")\n",
    "except NameError:\n",
    "    save_path = \"./research_data\"  # Fallback\n",
    "    print(\"Using fallback save path: research_data\")\n",
    "\n",
    "# Research cryptocurrency market trends with environment-aware file saving\n",
    "print(\"\\nüîç Cryptocurrency Research with Streaming:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Watch the agent work in real-time!\")\n",
    "print()\n",
    "\n",
    "crypto_research = agent.research_topic(f\"Bitcoin and Ethereum market trends 2026 to 2030. Save a full in-depth research document of all findings and commentary to {save_path}/crypto_analysis.md\")\n",
    "\n",
    "if crypto_research.get('error'):\n",
    "    print(f\"\\n‚ùå Research failed: {crypto_research['error']}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Research completed successfully!\")\n",
    "    print(f\"üìä Response status: {crypto_research.get('success', 'Unknown')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech Stocks Analysis for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research tech stock performance with environment-aware file saving\n",
    "try:\n",
    "    ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "    if ENV_TYPE == 'colab':\n",
    "        save_path = \"/content/proj-folder/research_data\"\n",
    "    else:\n",
    "        save_path = \"./research_data\"\n",
    "except NameError:\n",
    "    save_path = \"./research_data\"  # Fallback\n",
    "\n",
    "tech_stocks = agent.research_topic(f\"NVIDIA Apple Microsoft Google stock performance 2025 AI impact.\")\n",
    "\n",
    "print(\"üìà Tech Stocks Research Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if tech_stocks.get('error'):\n",
    "    print(f\"‚ùå Research failed: {tech_stocks['error']}\")\n",
    "else:\n",
    "    result = tech_stocks.get('result', {})\n",
    "    if 'content' in result:\n",
    "        print(result['content'])\n",
    "    else:\n",
    "        print(json.dumps(tech_stocks, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Market Sector Analysis\n",
    "\n",
    "Now let's analyze a specific market sector with iterative refinement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "    if ENV_TYPE == 'colab':\n",
    "        save_path = \"/content/proj-folder/research_data\"\n",
    "    else:\n",
    "        save_path = \"research_data\"\n",
    "except NameError:\n",
    "    save_path = \"research_data\"  # Fallback\n",
    "\n",
    "# Research renewable energy sector\n",
    "sector_analysis = agent.research_topic(f\"renewable energy stocks solar wind ESG investing trends 2025.\")\n",
    "\n",
    "print(\"üå± Renewable Energy Sector Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if sector_analysis.get('error'):\n",
    "    print(f\"‚ùå Research failed: {sector_analysis['error']}\")\n",
    "else:\n",
    "    result = sector_analysis.get('result', {})\n",
    "    if 'content' in result:\n",
    "        print(result['content'])\n",
    "    else:\n",
    "        print(json.dumps(sector_analysis, indent=2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining Generated Research Files\n",
    "\n",
    "Let's check what research files our agent has created and examine their contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# list files in the research directory\n",
    "research_dir = Path(\"./research_data\")\n",
    "\n",
    "if research_dir.exists():\n",
    "    files = list(research_dir.glob(\"*.txt\")) + list(research_dir.glob(\"*.md\")) + list(research_dir.glob(\"*.json\"))\n",
    "\n",
    "    print(f\"üìÅ Research Files Created ({len(files)} files):\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for file_path in files:\n",
    "        print(f\"üìÑ {file_path.name}\")\n",
    "        print(f\"   Size: {file_path.stat().st_size} bytes\")\n",
    "        print(f\"   Modified: {datetime.datetime.fromtimestamp(file_path.stat().st_mtime)}\")\n",
    "\n",
    "        # Show first few lines of each file\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read(500)  # First 500 characters\n",
    "                print(f\"   Preview: {content[:200]}...\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Error reading file: {e}\")\n",
    "\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Research directory not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Iterative Research Workflow\n",
    "\n",
    "Let's demonstrate a more complex iterative workflow where the agent:\n",
    "1. Performs initial research\n",
    "2. Analyzes gaps in the information\n",
    "3. Conducts follow-up searches\n",
    "4. Generates a comprehensive final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complex iterative research workflow with streaming\n",
    "async def complex_research_demo():\n",
    "    # Get environment-appropriate path for file saving\n",
    "    try:\n",
    "        ENV_TYPE, PROJ_PATH = detect_environment()\n",
    "        if ENV_TYPE == 'colab':\n",
    "            save_path = \"/content/proj-folder/research_data\"\n",
    "        else:\n",
    "            save_path = \"research_data\"\n",
    "        print(f\"Research files will be saved to: {save_path}\")\n",
    "    except NameError:\n",
    "        save_path = \"research_data\"  # Fallback\n",
    "        print(\"Using fallback save path: research_data\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Conduct a comprehensive multi-stage research analysis on \"Federal Reserve interest rate policy impact on financial markets 2024\".\n",
    "\n",
    "Please follow this iterative workflow:\n",
    "\n",
    "STAGE 1: Initial Information Gathering\n",
    "- Search for recent Fed policy announcements and decisions\n",
    "- Gather data on current interest rates and recent changes\n",
    "- Save initial findings to '{save_path}/fed_policy_initial.md'\n",
    "\n",
    "STAGE 2: Market Impact Analysis\n",
    "- Based on Stage 1 findings, search for specific market reactions\n",
    "- Focus on bond markets, stock markets, and currency impacts\n",
    "- Look for expert analysis and predictions\n",
    "- Save market analysis to '{save_path}/fed_policy_market_impact.md'\n",
    "\n",
    "STAGE 3: Sector-Specific Effects\n",
    "- Research how Fed policy affects different sectors (banking, real estate, tech)\n",
    "- Find specific examples of companies or sectors most impacted\n",
    "- Save sector analysis to '{save_path}/fed_policy_sectors.md'\n",
    "\n",
    "STAGE 4: Comprehensive Report\n",
    "- Synthesize all previous research into a final comprehensive report\n",
    "- Include executive summary, key findings, and future outlook\n",
    "- Save final report to '{save_path}/fed_policy_comprehensive_report.md'\n",
    "\n",
    "Please execute each stage sequentially and provide progress updates.\n",
    "\"\"\"\n",
    "\n",
    "    print(\"\\nüîç Advanced Iterative Research Workflow with Streaming:\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"This will demonstrate the complete iterative research process...\")\n",
    "    print()\n",
    "\n",
    "    # Stream the complex research\n",
    "    async def display_progress(chunk):\n",
    "        print(chunk, end='', flush=True)\n",
    "\n",
    "    result = await agent.send_message_stream(prompt, display_progress)\n",
    "\n",
    "    print(f\"\\n{'-' * 60}\")\n",
    "    if result.get('error'):\n",
    "        print(f\"‚ùå Research failed: {result['error']}\")\n",
    "    else:\n",
    "        print(\"‚úÖ Multi-stage research workflow completed!\")\n",
    "\n",
    "    return result\n",
    "\n",
    "# Execute the complex research\n",
    "complex_research = await complex_research_demo()\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis and Visualization\n",
    "\n",
    "Now let's analyze the research data we've collected and create some visualizations. This demonstrates how the agent can combine web search with local data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask agent to create a data analysis with visualizations\n",
    "analysis_request = await agent.send_message(\"\"\"\n",
    "Create a Python script that analyzes our research findings and generates visualizations.\n",
    "\n",
    "Please:\n",
    "1. Read all the research files we've created\n",
    "2. Extract key data points and trends\n",
    "3. Create a Python analysis script that includes:\n",
    "   - Text analysis of research findings\n",
    "   - Simple data visualizations (charts/graphs)\n",
    "   - Summary statistics\n",
    "4. Save the script as 'research_analysis.py'\n",
    "5. Execute the script to generate the analysis\n",
    "\n",
    "Focus on extracting quantitative data where possible (percentages, dates, financial figures).\n",
    "\"\"\")\n",
    "\n",
    "print(\"üìä Research Data Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if analysis_request.get('error'):\n",
    "    print(f\"‚ùå Analysis failed: {analysis_request['error']}\")\n",
    "else:\n",
    "    result = analysis_request.get('result', {})\n",
    "    if 'content' in result:\n",
    "        print(result['content'])\n",
    "    else:\n",
    "        print(json.dumps(analysis_request, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plugin Integration Demonstration\n",
    "\n",
    "Let's specifically demonstrate how the two plugins work together by having the agent:\n",
    "1. Search for specific financial data (Brave plugin)\n",
    "2. Process and store that data (Systools plugin)\n",
    "3. Create structured reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate explicit plugin integration\n",
    "plugin_demo = await agent.send_message(\"\"\"\n",
    "Demonstrate the integration between agentup_systools and agentup_brave plugins:\n",
    "\n",
    "1. Use Brave Search to find the latest stock prices for Apple (AAPL), Google (GOOGL), and Microsoft (MSFT)\n",
    "2. Use system tools to create a structured CSV file with the data\n",
    "3. Create a directory called 'stock_data' for organized storage\n",
    "4. Save the CSV file as 'top_tech_stocks.csv'\n",
    "5. Create a summary report explaining what you found and saved\n",
    "\n",
    "Please show each step clearly and explain how the plugins work together.\n",
    "\"\"\")\n",
    "\n",
    "print(\"üîß Plugin Integration Demonstration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if plugin_demo.get('error'):\n",
    "    print(f\"‚ùå Demo failed: {plugin_demo['error']}\")\n",
    "else:\n",
    "    result = plugin_demo.get('result', {})\n",
    "    if 'content' in result:\n",
    "        print(result['content'])\n",
    "    else:\n",
    "        print(json.dumps(plugin_demo, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Security Demonstration\n",
    "\n",
    "Let's test the agent's error handling and security features by attempting operations that might fail or require different permissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "# Test error handling and security\n",
    "print(\"üîí Testing Error Handling and Security:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def test_error_handling():\n",
    "\t# Test 2: File operation outside workspace (should be restricted)\n",
    "\trestricted_file = await agent.send_message(\"Create a file at /etc/restricted_file.txt\")\n",
    "\tprint(\"Test 2 - Restricted file location:\")\n",
    "\tprint(f\"Result: {restricted_file.get('error', 'Success')}\\n\")\n",
    "\n",
    "\t# Test 3: Large file handling\n",
    "\tlarge_file_test = await agent.send_message(\"Try to create a very large file (20MB) to test size limits\")\n",
    "\tprint(\"Test 3 - File size limits:\")\n",
    "\tprint(f\"Result: {large_file_test.get('error', 'Success')}\\n\")\n",
    "\n",
    "await test_error_handling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Research Summary\n",
    "\n",
    "Let's have the agent create a comprehensive summary of all the research we've conducted in this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive session summary\n",
    "session_summary = await agent.send_message(\"\"\"\n",
    "Create a comprehensive summary of all the financial research we've conducted in this session.\n",
    "\n",
    "Please:\n",
    "1. list all the research files you've created\n",
    "2. Summarize the key findings from each research topic\n",
    "3. Identify common themes and insights across all research\n",
    "4. Create a final report called 'session_summary_report.md'\n",
    "5. Include recommendations for further research\n",
    "\n",
    "This should serve as a complete overview of our financial research session.\n",
    "\"\"\")\n",
    "\n",
    "print(\"üìã Session Summary:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if session_summary.get('error'):\n",
    "    print(f\"‚ùå Summary failed: {session_summary['error']}\")\n",
    "else:\n",
    "    result = session_summary.get('result', {})\n",
    "    if 'content' in result:\n",
    "        print(result['content'])\n",
    "    else:\n",
    "        print(json.dumps(session_summary, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Learnings and Takeaways\n",
    "\n",
    "This notebook demonstrated several important concepts:\n",
    "\n",
    "### 1. **Plugin Architecture**\n",
    "- AgentUp's plugin system enables modular functionality\n",
    "- Plugins declare their capabilities and required scopes\n",
    "- Framework handles security enforcement automatically\n",
    "\n",
    "### 2. **Iterative Agent Design**\n",
    "- Agents can perform multi-step workflows\n",
    "- Each step builds on previous findings\n",
    "- Information is preserved between iterations\n",
    "\n",
    "### 3. **Security-First Approach**\n",
    "- Scope-based authorization provides fine-grained control\n",
    "- Plugins must declare required permissions\n",
    "- Framework fails securely when permissions are missing\n",
    "\n",
    "### 4. **A2A Protocol Integration**\n",
    "- Standardized communication format\n",
    "- JSON-RPC 2.0 for reliable message exchange\n",
    "- Authentication via API keys\n",
    "\n",
    "### 5. **Production Readiness**\n",
    "- Comprehensive error handling\n",
    "- Resource management and cleanup\n",
    "- Performance monitoring capabilities\n",
    "- Structured logging and audit trails\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "To extend this example:\n",
    "- Add more specialized financial data sources\n",
    "- Implement real-time data streaming\n",
    "- Create automated report scheduling\n",
    "- Add data visualization dashboards\n",
    "- Integrate with financial APIs (Alpha Vantage, Yahoo Finance)\n",
    "- Implement portfolio analysis capabilities\n",
    "\n",
    "## Resources\n",
    "\n",
    "- [AgentUp Documentation](https://docs.agentup.dev)\n",
    "- [Plugin Development Guide](https://docs.agentup.dev/plugin-development/)\n",
    "\n",
    "## Stay Updated\n",
    "\n",
    "AgentUp development is moving at a fast pace üèÉ‚Äç‚ôÇÔ∏è, for a great way to follow the project and to be instantly notified of new releases, **Star the [AgentUp Repository](https://github.com/RedDotRocket/AgentUp)**\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/RedDotRocket/AgentUp/refs/heads/main/assets/star.gif\" width=\"20%\" height=\"20%\"/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
